{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:34:06.374349Z",
     "start_time": "2024-11-11T16:34:06.316516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def loss(y, label):\n",
    "    diff = y - label\n",
    "    abs_diff = np.absolute(diff)\n",
    "    mean_diff = abs_diff.mean()\n",
    "    \n",
    "    return mean_diff\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, inputs):\n",
    "        # Веса и смещения инициализируются случайно\n",
    "        self._weights = np.random.rand(inputs)\n",
    "        self._bias = np.random.rand()\n",
    "        self._output = None\n",
    "        self._inputs = None\n",
    "        self._delta = None\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self._inputs = inputs\n",
    "        # Вычисление выхода через функцию активации (сигмоида)\n",
    "        self._output = sigmoid(np.dot(self._inputs, self._weights) + self._bias)\n",
    "        return self._output\n",
    "    \n",
    "    def backward(self, error):\n",
    "        # Ошибка на данном нейроне\n",
    "        self._delta = error * sigmoid_derivative(self._output)\n",
    "        \n",
    "        # Обновление весов и смещения\n",
    "        # Умножаем ошибку на вход для каждого нейрона и обновляем веса\n",
    "        self._weights -= self._delta * self._inputs\n",
    "        self._bias -= self._delta\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        # Создаем скрытые нейроны (2 нейрона с 2 входами)\n",
    "        self.hidden = [Neuron(2) for _ in range(2)]\n",
    "        # Выходной нейрон (с 2 входами, т.к. два скрытых нейрона)\n",
    "        self.output = Neuron(2)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # Прогон скрытого слоя\n",
    "        out_h = np.array([self.hidden[i].forward(inputs) for i in range(len(self.hidden))])\n",
    "        # Прогон выходного слоя\n",
    "        out_o = self.output.forward(out_h)\n",
    "        return out_o\n",
    "    \n",
    "    def backward(self, inputs, label):\n",
    "        # Рассчитываем ошибку на выходе\n",
    "        error = loss(self.output._output, label)\n",
    "        \n",
    "        # Обратное распространение для выходного слоя\n",
    "        self.output.backward(error)\n",
    "        \n",
    "        # Теперь вычисляем ошибку для скрытого слоя\n",
    "        hidden_errors = self.output._delta * self.output._weights\n",
    "        \n",
    "        # Обратное распространение для скрытых нейронов\n",
    "        for i in range(len(self.hidden)):\n",
    "            # Умножаем ошибку на вход для каждого скрытого нейрона\n",
    "            self.hidden[i].backward(hidden_errors * inputs[i])\n",
    "\n",
    "# Тренировочные данные (логический XOR)\n",
    "test = [[[0, 0], 0], [[0, 1], 1], [[1, 0], 1], [[1, 1], 0]]\n",
    "train = test\n",
    "model = Model()\n",
    "\n",
    "epoch = 1000\n",
    "for _ in range(epoch):\n",
    "    for X, label in train:\n",
    "        y = model.forward(X)  # Прогон модели\n",
    "        print(\"--- \", X, label)\n",
    "        model.backward(X, label)  # Обратное распространение\n"
   ],
   "id": "a87d6c29131d062f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  [0, 0] 0\n",
      "---  [0, 1] 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (2,) doesn't match the broadcast shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[382], line 79\u001B[0m\n\u001B[1;32m     77\u001B[0m y \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mforward(X)  \u001B[38;5;66;03m# Прогон модели\u001B[39;00m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--- \u001B[39m\u001B[38;5;124m\"\u001B[39m, X, label)\n\u001B[0;32m---> 79\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Обратное распространение\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[382], line 59\u001B[0m, in \u001B[0;36mModel.backward\u001B[0;34m(self, inputs, label)\u001B[0m\n\u001B[1;32m     56\u001B[0m error \u001B[38;5;241m=\u001B[39m loss(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39m_output, label)\n\u001B[1;32m     58\u001B[0m \u001B[38;5;66;03m# Обратное распространение для выходного слоя\u001B[39;00m\n\u001B[0;32m---> 59\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;66;03m# Теперь вычисляем ошибку для скрытого слоя\u001B[39;00m\n\u001B[1;32m     62\u001B[0m hidden_errors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39m_delta \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39m_weights\n",
      "Cell \u001B[0;32mIn[382], line 37\u001B[0m, in \u001B[0;36mNeuron.backward\u001B[0;34m(self, error)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_delta \u001B[38;5;241m=\u001B[39m error \u001B[38;5;241m*\u001B[39m sigmoid_derivative(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# Обновление весов и смещения\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# Умножаем ошибку на вход для каждого нейрона и обновляем веса\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_weights \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_delta \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inputs\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bias \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_delta\n",
      "\u001B[0;31mValueError\u001B[0m: non-broadcastable output operand with shape (2,) doesn't match the broadcast shape (2,2)"
     ]
    }
   ],
   "execution_count": 382
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:11:32.083405Z",
     "start_time": "2024-11-11T16:04:54.252642Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "20cc5a5fa8497e3e",
   "outputs": [],
   "execution_count": 370
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:11:32.083517Z",
     "start_time": "2024-11-11T16:04:54.265495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def loss(y, label):\n",
    "    diff = y - label\n",
    "    abs_diff = np.absolute(diff)\n",
    "    mean_diff = abs_diff.mean()\n",
    "    \n",
    "    return mean_diff\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n"
   ],
   "id": "2cd6daa50513d143",
   "outputs": [],
   "execution_count": 371
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:11:32.083572Z",
     "start_time": "2024-11-11T16:04:54.280246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Neuron:\n",
    "    def __init__(self, inputs):\n",
    "        self._weights = np.random.rand(inputs)\n",
    "        self._bias = np.random.rand()\n",
    "        self._output = None\n",
    "        self._inputs = None\n",
    "        self._delta = None\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        self._inputs = np.array(inputs)\n",
    "        self._output = sigmoid(\n",
    "            np.dot(self._inputs, self._weights) + self._bias\n",
    "        )\n",
    "        return self._output\n",
    "    \n",
    "    def backward(self, error):\n",
    "        self._delta = error * sigmoid_derivative(self._output)\n",
    "        \n",
    "        self._weights -= self._delta * self._inputs\n",
    "        self._bias -= self._delta"
   ],
   "id": "ca801c895118822b",
   "outputs": [],
   "execution_count": 372
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:11:32.083625Z",
     "start_time": "2024-11-11T16:04:54.292480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.hidden = [Neuron(2) for _ in range(2)]\n",
    "        self.output = Neuron(2)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        out_h = np.array([self.hidden[i].forward(inputs) for i in range(len(self.hidden))])\n",
    "        out_o = self.output.forward(out_h)\n",
    "        \n",
    "        return out_o\n",
    "    \n",
    "    def backward(self, inputs, label):\n",
    "        error = loss(self.output._output, label)\n",
    "        \n",
    "        self.output.backward(error)\n",
    "        hidden_errors = self.output._delta * np.array([neuron._weights for neuron in self.hidden])\n",
    "        for i in range(len(self.hidden)):\n",
    "            self.hidden[i].backward(hidden_errors[i] * inputs[i])\n"
   ],
   "id": "20db50c8c2b8dc2e",
   "outputs": [],
   "execution_count": 373
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:11:32.083676Z",
     "start_time": "2024-11-11T16:04:54.315980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = [[[0,0],0], [[0,1],1], [[1,0],1], [[1,1],0]]\n",
    "train = test"
   ],
   "id": "a1a92cb59e4cc5bb",
   "outputs": [],
   "execution_count": 374
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:11:32.083734Z",
     "start_time": "2024-11-11T16:04:54.332910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Model()\n",
    "epoch = 1000"
   ],
   "id": "1c95a15e0b418758",
   "outputs": [],
   "execution_count": 375
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-11T16:11:32.083780Z",
     "start_time": "2024-11-11T16:04:54.344255Z"
    }
   },
   "source": [
    "for _ in range(epoch):\n",
    "    for X, label in train:\n",
    "        y = model.forward(X)\n",
    "        print(\"--- \", X, label)\n",
    "        model.backward(X, label)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  [0, 0] 0\n",
      "---  [0, 1] 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (2,) doesn't match the broadcast shape (2,2)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[376], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m y \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mforward(X)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m--- \u001B[39m\u001B[38;5;124m\"\u001B[39m, X, label)\n\u001B[0;32m----> 5\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[373], line 15\u001B[0m, in \u001B[0;36mModel.backward\u001B[0;34m(self, inputs, label)\u001B[0m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, label):\n\u001B[1;32m     13\u001B[0m     error \u001B[38;5;241m=\u001B[39m loss(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39m_output, label)\n\u001B[0;32m---> 15\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m     hidden_errors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput\u001B[38;5;241m.\u001B[39m_delta \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39marray([neuron\u001B[38;5;241m.\u001B[39m_weights \u001B[38;5;28;01mfor\u001B[39;00m neuron \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden])\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden)):\n",
      "Cell \u001B[0;32mIn[372], line 19\u001B[0m, in \u001B[0;36mNeuron.backward\u001B[0;34m(self, error)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackward\u001B[39m(\u001B[38;5;28mself\u001B[39m, error):\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_delta \u001B[38;5;241m=\u001B[39m error \u001B[38;5;241m*\u001B[39m sigmoid_derivative(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output)\n\u001B[0;32m---> 19\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_weights \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_delta \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_inputs\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bias \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_delta\n",
      "\u001B[0;31mValueError\u001B[0m: non-broadcastable output operand with shape (2,) doesn't match the broadcast shape (2,2)"
     ]
    }
   ],
   "execution_count": 376
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:11:32.083840Z",
     "start_time": "2024-11-11T07:00:28.690440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for X, label in test:\n",
    "    print(f\"Input: {X}; Predict: {model.forward(X)}.\")"
   ],
   "id": "8eb4b944ef1fa26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: (0, 0); Predict: 1.0678820995742516e-11.\n",
      "Input: (0, 1); Predict: 0.5292391889465566.\n",
      "Input: (1, 0); Predict: 0.5292391889465566.\n",
      "Input: (1, 1); Predict: 0.5292391889465566.\n"
     ]
    }
   ],
   "execution_count": 252
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:11:32.083902Z",
     "start_time": "2024-11-11T07:00:28.767822Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "fc751d763d20bce",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
